<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>DNN-Hardware</title>
      <link href="/2022/05/27/DNN-Hardware/"/>
      <url>/2022/05/27/DNN-Hardware/</url>
      
        <content type="html"><![CDATA[<p>深度神经网络已被证明在视觉和音频识别任务中特别有效。<strong><font color="DarkViolet">因此，面向硬件的近似方法已成为一个热门话题。研究表明，定制的基于硬件的神经网络加速器在吞吐量和能效方面都可以超过其通用处理器。</font></strong>应用程序定制加速器与基于近似的网络训练方法共同设计时，可将大型、密集且计算昂贵的网络转换为小型、稀疏且硬件高效的替代方案，从而提高网络部署的可行性。在本文中，我们对高性能网络推理的近似方法进行了综合评估，并深入讨论了它们在定制硬件实现中的有效性。</p><hr><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>随着任务复杂性的增加，推理体系结构变得更加深入，计算成本也越来越高。最近的工作表明，通过使用近似，$DNN$部署变得更加可行，因为它减少了内存使用和计算复杂性。</p><p>$DNN$近似算法可分为两大类：</p><ol><li>定量方法会降低权重、激活（神经元输出）或两者的精度</li><li>权重修剪方法通过修剪和结构简化删除冗余参数</li></ol><p>我们在本文中评估这两种类型的方法，因为它们都有助于$DNN$加速。</p><p>多年来，通用处理器$（GPP）$，尤其是多核$CPU$和$GPU$，一直是$DNN$推理的主要硬件平台。对于未压缩的$DNN$模型，层操作映射到密集的浮点矩阵乘法，$GPP$可以按照单指令、多数据$（SIMD）$或单指令、多线程$（SIMT）$并行处理范式高效地并行处理这些运算。然而，在$DNN$近似下，使用自定义硬件平台（如现场可编程门阵列$（FPGA）$和专用集成电路$（ASIC）$来加速推理的趋势正在出现。虽然$GPU$仍然擅长密集浮点计算，但研究人员报告称，通过使用低精度定点量化，定制硬件的吞吐量和能效更高。此外，$SIMD$和$SIMT$体系结构在处理稀疏数据时表现不佳，通过细粒度减重压缩的$DNN$在定制硬件中执行效率更高,逻辑和内存层次结构的可定制性使自定义硬件$DNN$推理更快，更节能。</p><p>许多世界领先的信息技术公司已选择定制硬件实施其下一代$DNN$体系结构</p><ol><li>$Google’s \ Tensor \ Processing \ Unit (TPU) $</li><li>$ Intel \ Nervana $</li><li>$IBM \ TrueNorth$</li><li>基于$FPGA$的设计如$Microsoft \ Brainwave$和$Xilinx \ Everest$</li></ol><p>一般来说，$ASIC$设计可以实现最先进的吞吐量和能效？然而，它们耗时且需要资源的设计和制造过程使其难以跟上$DNN$算法的快速发展。</p><p>当然一些高级的实现工具，比如$OpenCL$，$Xilinx Vivado$高层分析工具等，使$FPGA$和$ASIC$的$DNN$硬件设计过程更快、更简单。</p><p>本文贡献：</p><ol><li>通过比较不同规模的可比$FPGA、ASIC、CPU和GPU平台的roofline \ model$，激发了定制硬件的$DNN$近似。</li><li>我们调查了最新$DNN$近似的主要趋势。我们详细介绍了低精度量化和权重修剪的方法，介绍了最近的算法发展，并评估了它们的相对优势和劣势。</li><li>评估每种方法的定制硬件实现的性能，重点是准确性、压缩、吞吐量、延迟和能效。</li><li>提出了未来研究的几个有希望的方向</li></ol><hr><h2 id="评估指标"><a href="#评估指标" class="headerlink" title="评估指标"></a>评估指标</h2><ol><li>准确率</li><li>压缩率</li><li>吞吐量</li><li>延迟</li><li>能量效率</li></ol><hr><h2 id="为什么定制硬件"><a href="#为什么定制硬件" class="headerlink" title="为什么定制硬件"></a>为什么定制硬件</h2><p>对于$DNN$的推理，近似在三个方面有助于提高吞吐量：提高并行性、减少内存传输和减少工作量，借助$roofline \  modeling$，可以解释每个因素的贡献，揭示为什么自定义硬件可以从近似中挤出比$GPP$更多的加速。</p><p>$roofline \  modeling$捕捉了加速平台的理论峰值性能，同时也反映了片外存储器数据传输的影响。对于任何高性能计算引擎，峰值算术性能（以$op/$秒表示）受到两个因素的限制：<strong><font color="DarkViolet">内存带宽和可用计算资源量</font></strong></p><ol><li>内存带宽限制了激活的读取和写的速率，以及可以获取片外存储的参数的值。</li><li>计算资源，指的是能够执行运算（主要是乘法）的片上并行处理单元。</li></ol><p>当内存受限时，平台的算术性能不会随着并行度的增加而增加。同时，在计算范围内，所有可用的处理资源都已饱和。</p><p><img src="/2022/05/27/DNN-Hardware/image-20220527135040680.png" alt="image-20220527135040680"></p><p>横坐标表示$DNN$推理的算术强度，纵坐标表示算术表现。算术强度通常也称为操作强度或计算与通信$（CTC）$比率，表示为每字节片外内存流量$（op /B）$执行的算术运算数。<strong><font color="DarkViolet">算术强度在$break \  point$左侧的时候是内存限制，在右侧的时候则是计算限制</font></strong></p><h3 id="计算边界的灵活性"><a href="#计算边界的灵活性" class="headerlink" title="计算边界的灵活性"></a>计算边界的灵活性</h3><p>可以观察到，由于其对浮点算术运算的专业支持，$GPU$可以为$FP32 DNN$推理提供最高的算术性能。然而，当从浮点数据转换为精度较低的定点数据表示时，自定义硬件设计的灵活性有助于在精度与性能之间进行权衡。</p><h3 id="网络压缩提高了算法性能"><a href="#网络压缩提高了算法性能" class="headerlink" title="网络压缩提高了算法性能"></a>网络压缩提高了算法性能</h3><p>只有在执行应用程序不受其内存限制的情况下，才能达到平台的计算边界。如果是，那么，为了获得更高的运算性能，需要更高的运算强度。<strong><font color="DarkViolet">通过以精度降低的形式进行网络压缩，每次执行的操作需要访问的片外内存更少，因此，如果应用程序不受计算限制，则可以实现更高的运算强度和随后的性能。</font></strong>还可以通过减轻权重来压缩网络，这样既节省了内存，又无需执行相关操作，还可以提高运算强度，从而提高性能：较小的网络可以更有效地使用片内缓存，减少甚至完全消除片外内存流量。</p><p>从$roofline \  modeling$可以分析，当受内存限制时，算术强度的增加意味着沿屋顶线向右移动，从而导致算术性能的提高。虽然所有的硬件平台都可以从网络压缩中受益，但自定义硬件实现，具有比$GPPs$更高的计算边界，将获得最大的收益;当计算强度增加时，$GPPs$会更早地到达计算边界。</p><h3 id="局限性"><a href="#局限性" class="headerlink" title="局限性"></a>局限性</h3><p>虽然屋顶线模型可以预测由于通过近似获得的并行性增加和内存传输减少而导致的算术性能的提高（以$op/s$为单位），但它们只能在有限的范围内捕获吞吐量$(cl/s)$的相应变化。为了了解权重修剪方法对吞吐量的影响，我们必须考虑一个额外的因素。算术性能和吞吐量与工作负载$（op /cl）$相关：每个分类执行的算术运算数。</p><p>权重修剪删除了不重要的参数，这些方法实现了同时的内存传输和工作量减少。由于内存传输的减少可以促进算术性能的提高，因此吞吐量的提高有可能超过通过使用实现的算术性能。</p><p>定量的方法，另一方面，由于每种分类执行的操作数量保持不变，因此反定位方法不会减少工作量。对于这些，算术性能的提高会导致吞吐量的成比例增加。</p><p>虽然$DNN$近似会导致信息丢失和随后的精度下降，但本文调查的大多数作品表明，在准确性方面做出适当的牺牲可以显著提高性能。本文的其余部分重点分析了网络压缩和准确性之间的权衡。</p><p>延迟关键的$DNN$应用程序，如高级驾驶辅助系统，要求快速生成分类。许多用户界面应用程序也需要低延迟来维持足够的用户体验。$Roofline$模型本身并不捕获延迟。在此，我们详细介绍了定制硬件如何凭借其灵活性实现最先进的$DNN$推理延迟和吞吐量。</p><p>自定义的基于硬件的$DNN$推断应用程序在较低的时钟频率下运行，因此功耗较低，与在$GPPs$上运行的系统相比，具有更高的吞吐量和/或更低的延迟。此外，一些实现通过利用可定制性，在内存能效方面优于基于$GPU$的版本。</p><hr><h2 id="量化"><a href="#量化" class="headerlink" title="量化"></a>量化</h2><p>第一个主要近似主题是定量。$FPGA$和$ASIC$的灵活性允许实现低精度$DNN$，从而通过并行化和减少对慢片外存储器的依赖来提高吞吐量。</p><h3 id="定点表示法"><a href="#定点表示法" class="headerlink" title="定点表示法"></a>定点表示法</h3><h4 id="算法开发"><a href="#算法开发" class="headerlink" title="算法开发"></a>算法开发</h4><p>浮点量化的$DNN$通常允许对每个单独参数使用任意的二进制点位置，即指数值。然而，数据表示范围的灵活性是以牺牲高资源使用、电力消耗和算术运算延迟为代价的。定点量化$DNN$通常使用一致的，预定的精度和二进制点位置，即相等的最大和最小可表示的大小，对整个网络。允许在硬件中进行快速、廉价和节能的算术操作，但强制使用不变的数据表示范围。有些工作进行了证明：</p><ol><li>$Courbariaux$等人对这个主题进行了调查，表明即使在低精度的定点格式下进行前向传播，$CNN$推理的准确性仍然可以保持</li><li>$Jacob$等人对流行的CNN模型$MobileNet$进行了8位量化，报告称在$ARM \  CPU$上的推断延迟减少了高达$50%$，而对$COCO$数据集的准确率仅下降了$1.8$。</li><li>许多作者提出了基于$FPGA$的$CNN$和$RNN$推理框架，使用低精度定点格式，实现了优于浮点格式的吞吐量，精度下降可以忽略不计。<strong><font color="DarkViolet">然而，由于不同层的数据可能有非常不同的范围，因此对整个网络使用恒定的量化分辨率可能会提供次优带宽效率。</font></strong></li></ol><p>$Courbariaux$等人，$Qiu$等人和$Shin$等人探索了使用块浮点$(BFP)$进行权重和激活量化。变量组共享共同的二进制点位置，表示为根据数据分布在训练期间更新的比例因子。因此，它可以被视为完全浮点格式和定点格式之间的折衷。这些作者将每一层的参数与一个比例因子相关联，通过在训练时检查参数的溢出状态，在每次运算后更新。他们的实验表明，对于$CNNs$和$RNNs$, $BFP$对权重和激活量的量化会导致低于$1.0 pp$的精度损失。从那时起，$BFP$在$DNN$的硬件推断中也变得普遍。</p><p>许多作者已经探索了允许自动选择分层精度的方法</p><ol><li>受$Sung$等人的启发，$Shin$等人通过分析信量化噪声比$(SQNR)$和精度之间的权衡，提出了在长短期记忆$(LSTMs)$中使用成本最优精度的彻底搜索。然而，这种搜索的时间复杂度太高，不切实际。</li><li>邱等人制定了一个优化问题，以使关于精度和二进制点位置变化的量化误差最小化。提出了一种贪婪的方法来求解它，得到了令人满意的分层$CNN$量化。</li><li>Lin等人制定并解决了一个基于$SQNR$的优化问题，以确定定制设计的CNN的每层最优定点精度，表明所提出的方案为$CIFAR-10$数据集提供了超过$1.2×$压缩，而不损失精度。</li></ol><p>他们的方法将$FP32$中预训练的网络转化为进一步量化的等效网络，而无需再训练。</p><p>许多作者着重于通过修改舍入方案来减少精度损失。</p><ol><li>$Gupta$等人使用随机舍入的$16$位定点权重表示训练$CNNs$，实现$MNIST和cifar10$数据集的无损压缩。通过</li><li>$Wu$等人提出了$WAGE$，一种利用随机舍入离散梯度的$CNN$框架。$AlexNet$使用2个比特用于权重，8个比特用于激活、梯度和错误，用$WAGE$对$ImageNet$进行分类的训练显示出大约8.8 pp的准确性下降。</li><li>$Shin$等人探索了将量化分辨率作为$CNNs$和$RNNs$的可训练参数。通过可调的量化粒度，对$SVHN$数据集进行分类的4位$CNN$和执行语言建模的6位$RNN$的精度损失均小于0.1 pp。</li></ol><p>虽然前面提到的所有作品都采用定点格式量化权重，但$Lai$等人使用浮点权值和定点激活实现了$CNN$推断。$AlexNet$上的实验表明，使用7位浮点权值可以达到与$ImageNet$上的11位定点表示相同的精度。</p><p>自适应量化法的作者在比前面提到的逐层方法更细的粒度上研究量化。在再训练过程中，网络会进行调整，每个过滤器都被允许假定一个独立的精度。对小规模数据集和模型的实验表明，自适应量化法与剪枝相结合，能够获得优于二值化神经网络的精度和压缩比，二值化神经网络的每个数据只使用一个比特来表示。$DoReFa-Net$是一个实现低精度量化的框架，支持从32位定点到二进制的任意精度的权重、激活和梯度。它的作者对各种数据精度组合进行了实证分析，得出结论，当权重和/或激活被量化到少于4位时，精度会迅速下降。</p><h4 id="硬件实现"><a href="#硬件实现" class="headerlink" title="硬件实现"></a>硬件实现</h4><p>$Nurvitadhi$等人通过实验评估了使用浮点和定点数据表示的$Nvidia \ GPUs$和$Intel \ FPGAs$对$CNN$推理的性能。虽然他们评估的$Stratix-10 \ FPGA$的吞吐量落后于带有$FP32$的$Titan \ X \ GPU$，但$FPGA$在6位定点数据下可以实现超过其50%的吞吐量。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>DARTS(ICLR 2019)</title>
      <link href="/2022/05/26/DARTS/"/>
      <url>/2022/05/26/DARTS/</url>
      
        <content type="html"><![CDATA[<p><strong><font color="Salmon">paper</font></strong>: <a href="https://arxiv.org/abs/1806.09055">https://arxiv.org/abs/1806.09055</a><br><strong><font color="Salmon">code</font></strong>: <a href="https://github.com/quark0/darts">https://github.com/quark0/darts</a></p><p><br></p><p>发现最先进的神经网络结构需要人类专家的大量努力。最近，人们对开发算法解决方案以自动化架构设计的手动过程越来越感兴趣。自动搜索的体系结构在图像分类和目标检测等任务中取得了极具竞争力的性能。</p><p>传统的$NAS$方法基本上都分为2个步骤：一个是搜索结构（这通常在<strong>验证集val</strong>上进行），一个步骤是在搜索好的结构上做验证（这通常在<strong>训练集train</strong>上进行）。众所周知，如果不是太小的数据集，类似$CIFAR-10$这样的，那第二个步骤还是比较花费时间。这篇文章提出了一种新的松弛方法以解决这个问题。</p><p>现有的最佳体系结构搜索算法尽管性能卓越，但计算要求很高。</p><p>已经提出了几种加速的方法，例如</p><ol><li>强制实施搜索空间的特定结构$（Liu等人，2018b；a）$</li><li>每个架构的权重或性能预测$（Brock等人，2018；Baker等人，2018）$</li><li>以及跨多个架构的权重共享/继承$（Elsken等人，2017；Pham等人，2018b；Cai等人，2018；Bender等人，2018）$</li></ol><p><strong><font color="DarkViolet">但可扩展性的根本挑战仍然存在。主流方法效率低下的一个内在原因是，架构搜索被视为离散域上的黑盒优化问题，这导致需要进行大量架构评估</font></strong>。</p><p>在这项工作中，我们从不同的角度来处理这个问题，<strong><font color="DarkViolet">并提出了一种高效的架构搜索方法，称为$DARTS$（可差分架构搜索）。我们没有在一组离散的候选体系结构上进行搜索，而是将搜索空间放宽为连续的，这样就可以通过梯度下降来优化体系结构的验证集性能。</font></strong>基于梯度的优化的数据效率，与低效的黑盒搜索相反，使$DARTS$能够使用数量级更少的计算资源，实现与最先进水平相竞争的性能。它还优于另一种最近有效的架构搜索方法$ENAS（Pham等人，2018b）$。</p><p>虽然之前的工作试图微调架构的特定方面，例如卷积网络中的过滤器形状或分支模式，但$DARTS$能够在丰富的搜索空间中学习具有复杂图形拓扑的高性能架构构建块。此外，$DARTS$不局限于任何特定的体系结构族，并且适用于卷积网络和递归网络。</p><p><strong><font color="DarkViolet">$DARTS$实现了显著的效率提高（将架构发现的成本减少到几天$GPU$），这归功于使用基于梯度的优化，而不是不可微搜索技术。(注意：DARTS是可微的！！！)</font></strong></p><h2 id="方法介绍"><a href="#方法介绍" class="headerlink" title="方法介绍"></a>方法介绍</h2><p>分为三个部分</p><ol><li>有向无环图表示的搜索空间</li><li>简单的连续松弛方案，该方案为架构及其权重的联合优化提供了一个可微的学习目标</li><li>提出了一种近似技术，使算法在计算上可行且高效</li></ol><p>下面展开</p><hr><h3 id="搜索空间"><a href="#搜索空间" class="headerlink" title="搜索空间"></a>搜索空间</h3><p>一个$cell$是由$N$个节点的有序序列组成的有向无环图。<strong><font color="DarkViolet">每个节点$x^{(i)}$是潜在表示（例如卷积网络中的特征映射），每个有向边$（i，j）$与变换$x^{(i)}$的操作$o^{(i,j)}$相关联。每个中间节点基于其所有前置节点进行计算</font></strong>：</p><script type="math/tex; mode=display">x^{(j)}=\sum_{i<j}o^{i,j}(x^{(i)})</script><p>还包括一个特殊的零操作，以指示两个节点之间缺少连接。因此，学习单元的任务简化为学习其边缘的操作。</p><h3 id="连续松弛优化"><a href="#连续松弛优化" class="headerlink" title="连续松弛优化"></a>连续松弛优化</h3><p>设$O$是一组候选操作（例如卷积、最大池、零），其中每个操作表示要应用于$x^{(i)}$的某个函数$o^{(i,j)}$。为了使搜索空间连续，我们使用$softmax$松弛所有可能的操作：</p><script type="math/tex; mode=display">\bar o^{(i,j)}(x)= \sum_{o \in O} \frac{exp(\alpha_o^{(i,j)})}{\sum_{o' \in O} exp(\alpha_{o'}^{(i,j)})}o(x)</script><p><strong><font color="DarkViolet">所以两个节点之间每个操作的权重可以被参数化为一个维度为$|O|$的$\alpha^{(i,j)}$，架构搜索的任务简化为学习一组连续变量$\alpha = \left\{ \alpha^{(i,j)} \right\}$</font></strong></p><p><br></p><p><img src="/2022/05/26/DARTS/image-20220526210413087.png" alt="image-20220526210413087"></p><p><br></p><p>这里我理解是假如在图(b)中要算节点0和节点1之间的$\bar o^{(i,j)}(x)$，假设有三个操作，$softmax$以后对应的比例为$\frac{1}{5}$,$\frac{2}{5}$,$\frac{2}{5}$则</p><script type="math/tex; mode=display">\bar o^{(i,j)}(x) = \frac{1}{5}op1 + \frac{2}{5}op2 + \frac{2}{5}op3</script><p>在搜索结束时，通过替换每个混合操作$\bar o^{(i,j)}(x)$可以获得离散的体系结构,</p><script type="math/tex; mode=display">\bar o^{(i,j)}(x) =  argmax_{o \in O} \alpha_o^{(i,j)}</script><p>在下文中，我们将α称为结构的编码。</p><p>在进行了$softmax$松弛之后，我们的目标是共同学习所有混合运算中的结构$\alpha$和权重$w$（例如卷积滤波器的权重）。与使用$RL$或$evolution$进行架构搜索类似，DARTS旨在优化验证损失，但使用梯度下降。</p><p>定义$L_{train}$和$L_{val}$为训练和验证的损失，这两个损失不仅决定了$\alpha$，还决定了网络中的权重$w$,所有搜索架构的目标就是找到一个$\alpha^*$, 最小化验证损失$\mathcal L_{val}(w^{\star},\alpha^{\star})$其中重量 $w^{\star}$通过最小化训练损失 $\mathcal L_{train}(w,\alpha^{\star})$获得</p><p><br></p><p>所以这就是一个双向优化的任务：</p><script type="math/tex; mode=display">\min_{\alpha} \ \mathcal L_{val}(w^*(\alpha),\alpha) \\s.t. \ w^*(\alpha)=argmin_w \ \mathcal L_{train}(w,\alpha)</script><h3 id="近似架构梯度"><a href="#近似架构梯度" class="headerlink" title="近似架构梯度"></a>近似架构梯度</h3><p>由于代价高昂的内部优化，准确评估架构梯度可能会让人望而却步。因此，我们提出一个简单的近似方案如下：</p><script type="math/tex; mode=display">\nabla_{\alpha} \mathcal L_{val}(w^*(\alpha),\alpha) \\\approx \nabla_{\alpha} \mathcal L_{val}(w- \xi\nabla_{\alpha}\mathcal L_{train}(w,\alpha),\alpha)</script><p>其中$w$是当前的权重，$\xi$是内部优化的学习率，这个优化 $w^*(\alpha)$的想法是使用单步优化，而不是通过训练直到收敛来解决内部优化，如果 $w$已经是内部最优，则$\nabla_{\alpha}\mathcal L_{train}(w,\alpha)=0$</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">相关技术已用于模型转移的元学习（Finn等人，2017年）、基于梯度的超参数调整（Luketina等人，2016年）和展开的生成性对抗网络（Metz等人，2017年）</span><br></pre></td></tr></table></figure><p><img src="/2022/05/26/DARTS/image-20220526222732827.png" alt="image-20220526222732827"></p><p><br></p><p><strong><font color="DarkViolet">接下来就是本文最大的贡献和亮点：</font></strong></p><p>说了这么一大堆，其实就是为了引出下面2个公式。首先，作者是说使用$chain \ rule$(链式法则)可以将上面近似后的式子化简为：</p><script type="math/tex; mode=display">\nabla_{\alpha} \mathcal L_{val}(w- \xi\nabla_{\alpha}\mathcal L_{train}(w,\alpha),\alpha) = \nabla_{\alpha} \mathcal L_{val}(w',\alpha)- \xi\nabla_{\alpha,w}^2\mathcal L_{train}(w,\alpha) \cdot \nabla_{w'}\mathcal L_{val}(w',\alpha)</script><p>看着复杂，其实就是一个关于 $\alpha$的复合函数求导，其实就是可以看作 $\nabla_{\alpha} f(g_1(\alpha),g_2(\alpha))$，其中 $f(\cdot,\cdot)=\mathcal L_{val}(\cdot,\cdot)$， $g_1(\alpha)=w- \xi\nabla_{\alpha}\mathcal L_{train}(w,\alpha)$，$g_2(\alpha)=\alpha$</p><p><br></p><p><img src="/2022/05/26/DARTS/image-20220526230243667.png" alt="image-20220526230243667"></p><p><br></p><p>这里的$D_1f(g_1(\alpha),g_2(\alpha))$就是 $f(g_1(\alpha),g_2(\alpha))$对 $g_1(\alpha)$求导，这里的 $w’$就表示的 $w- \xi\nabla_{\alpha}\mathcal L_{train}(w,\alpha)$这个整体，$D_2f(g_1(\alpha),g_2(\alpha))$同理</p><p>将上面的四项带入到 $\nabla_{\alpha} \mathcal L_{val}(w- \xi\nabla_{\alpha}\mathcal L_{train}(w,\alpha),\alpha)$当中就可以得到上式的后面部分了</p><p>当然还要计算最后两项的乘积即 $\xi\nabla_{\alpha,w}^2\mathcal L_{train}(w,\alpha) \cdot \nabla_{w’}\mathcal L_{val}(w’,\alpha)$，该如何计算呢？要用到一阶的泰勒公式展开</p><p><br></p><p><img src="/2022/05/26/DARTS/image-20220526231345786.png" alt="image-20220526231345786"></p><p><br></p><p>当 $\xi=0$时，$\xi\nabla_{\alpha}\mathcal L_{train}(w,\alpha)$将消失。在这种情况下，架构梯度由以下公式给出$\nabla_{\alpha} \mathcal L_{val}(w,\alpha)$，对应于通过假设当前$w$与$w^*(\alpha)$相同来优化验证损失的简单方式，这样虽然可以加速，但是性能会差。</p><p>我们引用$\xi=0$的情况作为一阶近似，引用$\xi &gt;0$的梯度公式作为二阶近似。</p><hr><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol><li><strong><font color="Salmon">其实主要思想就是搜索空间的定义和联合的训练架构参数$\alpha$和操作参数$w$，公式的推导也透彻了，但是对具体的实现还是存疑，不知道到底是怎么样的优化过程，明天专门看代码分析一下实现过程。</font></strong></li><li><strong><font color="Salmon">这篇文章其实看过两次了，但是没有做好总结，教训</font></strong></li></ol>]]></content>
      
      
      <categories>
          
          <category> Paper Reading </category>
          
          <category> Neural Architecture Search </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NAS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Reliable Deep Graph Learning(中山大学 &amp; 腾讯)</title>
      <link href="/2022/05/25/ReliableDGL/"/>
      <url>/2022/05/25/ReliableDGL/</url>
      
        <content type="html"><![CDATA[<p><strong><font color="Salmon">paper</font></strong>: <a href="https://arxiv.org/abs/2202.07114v1">https://arxiv.org/abs/2202.07114v1</a></p><p><br></p><p>首先本笔记只是记录一下分类，如果有感兴趣的论文找到原论文中的对应位置找到索引阅读即可</p><p>深度图学习$（Deep \ Graph \ Learning，DGL）$在各领域都取得了显著的进步。尽管取得了进展，但将$DGL$应用于实际应用仍面临一系列可靠性威胁，包括<strong><font color="DarkViolet">固有噪声、分布偏移和对抗性攻击</font></strong>。</p><p>这篇综述也是从这三个方面对图学习可靠性的最新进展进行了总结。</p><ol><li>固有噪声是指图结构、节点属性和节点/图标签中的不可约噪声。</li><li>分布转移是指训练分布和测试分布之间的转移(如$shift-GNN$)</li><li>对抗性攻击是一种操纵性的人类行为，旨在通过精心设计的模式或对原始数据的扰动导致模型不当行为。</li></ol><p>下图显示了在深度图学习的典型管道中，不同的威胁是如何发生的。相比之下，由于采样偏差或环境噪声，在数据生成过程中通常会发生固有噪声或分布偏移，而没有经过刻意的人为设计，而恶意攻击者在数据生成阶段之后故意设计了对抗性攻击。</p><p><br></p><p><img src="/2022/05/25/ReliableDGL/image-20220525182805066.png" alt="image-20220525182805066"></p><hr><h2 id="抗固有噪声的可靠性"><a href="#抗固有噪声的可靠性" class="headerlink" title="抗固有噪声的可靠性"></a>抗固有噪声的可靠性</h2><p>现实世界中的图形数据不可避免地会包含一些固有的噪声，这些噪声可能来自容易出错的数据测量或收集、数据预处理过程中的信息丢失、次优图形结构，下游任务等。</p><p>固有噪声可能存在于图结构、节点属性和节点/图标签中，这引出了三种类型的固有噪声，即<strong><font color="DarkViolet">结构噪声、属性噪声和标签噪声</font></strong>。</p><ol><li><strong><font color="Salmon">结构噪声</font></strong>是由于容易出错的数据测量或收集，例如蛋白质-蛋白质相互作用网络，不可避免地引入固有结构噪声。</li><li><strong><font color="Salmon">属性噪声</font></strong><ol><li>一方面，节点的原始属性可能不完整或不正确。例如，由于社交网络中的隐私问题，用户可能会故意提供虚假的个人资料。</li><li>另一方面，原始节点属性转换为节点嵌入时的信息丢失，例如，使用单词嵌入技术对节点的文本数据进行编码。在基于消息传递的$GNNs$的训练阶段，每个节点中的属性噪声可以传递给其邻居，这将逐渐影响最终的节点/图嵌入。</li></ol></li><li><strong><font color="Salmon">标签噪声</font></strong> <ol><li>节点或图形标签中的错误注释会导致固有的标签噪声。与图像分类类似，节点分类中可能会出现不可避免的错误注释。<strong><font color="DarkViolet">但与图像相比，由于图中的节点依赖性，可能更难为节点标注标签，这会导致更多噪声或标签稀疏性问题</font></strong></li><li>在图分类中，由于需要更多的领域专业知识，为图添加标签的成本变得更高。例如，要注释分子图的药物相关特性，需要进行测量实验或从文献中提取特性，这两者都可能引入图形标签噪声</li></ol></li></ol><h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><ol><li>数据去噪<ol><li>数据去噪是减少$DGL$算法中噪声影响的一种简单方法。对于结构噪声，一个自然的想法是在$GNNs$中执行节点信息聚合时为每个节点分配可学习的权重，以便权重能够反映任务所需的图结构。有如下的一些论文，可以根据需要取论文里找参考链接<ol><li>将自我注意模块整合到原始GNN中方法</li><li>使用多层神经网络修剪任务无关边，以从学习的分布中绘制子图</li><li>重新参数化技巧</li></ol></li><li>对于标签噪声会导致$DGL$设置中的性能显著下降。<ol><li>有的工作直接应用后向损失标签校正来训练$GNN$，而不考虑图结构。</li><li>有的工作将结构信息纳入了设计中。通过使用标签聚合图结构上的随机游动来估计节点级类概率分布，从而进行样本重新加权和标签校正。</li><li>建议生成准确的伪标签，并在未标记节点和（伪）标记节点之间分配高质量边缘，以减少标签噪声。</li></ol></li><li><strong><font color="DarkViolet">尽管存在属性噪声，但据我们所知，目前还没有专门设计用于去除属性噪声的方法，这可能是一个很有前途的方向。</font></strong></li></ol></li><li>具有正则化的$DGL$<ol><li>从正则化的角度来看，以往的研究试图通过隐式或显式降低假设空间的复杂性来减少对固有噪声的过度拟合。一方面，为了减少$DGL$算法的过拟合，提出了各种专门用于$GNN$的正则化技术。<ol><li>核心思想是随机删除边、节点或$GNN$的隐藏表示。最近有工作进一步将这些方法统一到贝叶斯图学习框架中。</li><li>此外，一种先进的数据增强策略，即混合，最近被应用于$DGL$，并被证明对多个与图形相关的任务是有效的</li><li>有一些研究试图显式地将正则化施加到假设空间，即构建具有一些预定义约束或归纳偏差的$GNN$模型</li><li>从贝叶斯的角度来看，DGL的先验集成方法也可以看作是一种隐式正则化，它通过不同的输入数据转换独立训练多个图学习模型，然后将多个模型的输出聚合为最终输出</li></ol></li></ol></li></ol><h2 id="抗分布偏移的可靠性"><a href="#抗分布偏移的可靠性" class="headerlink" title="抗分布偏移的可靠性"></a>抗分布偏移的可靠性</h2><p>当训练数据和测试数据由不同的底层分布生成时，机器学习中的分布会发生变化，这在许多实际应用中都存在。本节首先对图形数据上的典型分布偏移进行分类，然后介绍最近为提高$DGL$方法对分布偏移的可靠性所做的工作。</p><p>图结构数据的分布迁移分为两类：$domain \ generalization$和$sub-population shift$。</p><ol><li>$domain \ generalization$是指训练和测试分布由不同的领域组成。一些典型的例子包括协变量移位和开集识别。<ol><li>协变量移位，它假设训练域和测试域的条件标签分布相同，但数据边缘分布不同。例如，在药物发现中，药物分子的支架往往在推理上有所不同，在社交网络和金融网络中，图形结构可能会随着时间发生显著变化</li></ol></li><li>$sub-population \ shift$指的是训练和测试分布由同一组域组成，但每个域的频率不同。<ol><li>当数据/标签$sub-population$的频率发生变化时，图上的$sub-population \ shift$会增加</li><li>标签偏移是指两个域的边缘标签分布发生变化，但输入给定标签的条件分布在域之间保持不变的情况</li><li>此外，图上的分类平衡问题是标签转移的一种特殊形式。例如，标签分布对于测试分布是统一的，但对于训练分布则不统一。</li></ol></li></ol><h3 id="方法-1"><a href="#方法-1" class="headerlink" title="方法"></a>方法</h3><ol><li>不变图表示学习<ol><li>不变图表示学习旨在学习跨不同领域的不变图表示。最近提出的不变表示学习的思想已经在一些$DGL$模型中得到了应用。<ol><li>使用因果模型来学习近似不变的图表示，这些图表示可以很好地在训练域和测试域之间进行外推。</li><li>有的工作继承不变风险最小化的精神，开发一个探索外推风险最小化框架，促进$GNNs$利用不变图特征进行节点级预测。</li><li>设计一个对抗性域分类器，学习网络对齐的域不变表示，通过同时最小化损失和最大化观测锚的后验概率分布，对其进行优化。</li><li>提出了一种基于解纠缠的无监督域自适应方法，该方法应用变分图自动编码器来恢复三种类型的定义潜在变量（语义、域和随机潜在变量）。</li></ol></li></ol></li><li>图鲁棒性训练<ol><li>图鲁棒训练提出通过增加数据或修改训练框架来增强模型对分布变化的鲁棒性。一方面，一些方法将高级数据增强技术推广到通用数据格式（例如，混合）中，以绘制结构化数据。<ol><li>提出了一种基于混合的框架，用于改进图上的类不平衡节点分类，该框架在构建的语义关系空间和边缘混合上执行特征混合。</li><li>提出了一个基于节点特征和图结构的公平性感知数据增强框架，以减少$GNNs$获得的节点表示的固有偏差。</li></ol></li><li>另一方面，一些方法建议在$DGL$模型中集成对抗性训练技术。<ol><li>提出了一种方法，该方法在训练期间通过对抗性扰动迭代增强节点特征，并通过使模型对输入数据的小波动保持不变，帮助模型推广到$out-of-distribution（OOD）$样本。</li><li>利用注意机制整合全局和局部一致性以及梯度反转层来学习跨域节点嵌入。</li></ol></li></ol></li><li>不确定度量化<ol><li>除了上述两个旨在提高模型稳健性的方向外，不确定性量化可被视为增强$DGL$算法可靠性的补充方法，因为估计的不确定性可用于拒绝具有高模型预测不确定性的不可靠决策。自然不确定性度量可以是预测置信度，即$Softmax$输出的最大值。然而，最近的研究发现，具有$Softmax$预测层的$GNN$通常信心不足，因此信心不能准确反映预测的不确定性，两种方法解决<ol><li>将概率块引入到原始$GNN$中，用于建模后验权重分布，这可以提供比确定性$GNN$架构更精确的不确定性估计。例如，有工作提议用高斯过程块代替$Softmax$决策层，该过程块可提供准确的不确定性估计。</li><li>贝叶斯$GNN$积极地将整个$GNN$层转换为贝叶斯对应层。具体而言，它将模型权重和抽样过程都视为概率分布，并采用变分推理来估计这些分布的参数。</li><li>其次，更直接的方法是以事后方式执行置信度校准，而不修改$GNN$体系结构。一种典型的校准方法是温度定标。然而，它最初是为$DNN$设计的，经证明在$DGL$设置中性能较差。有工作通过使用额外的$GNN$预测每个节点的唯一温度，修改$GNN$的温度标度。由于温度是通过同时考虑节点特征和图形拓扑来产生的，因此该方法比原方法具有更好的标定性能。</li></ol></li></ol></li></ol><h2 id="对抗对手攻击的可靠性"><a href="#对抗对手攻击的可靠性" class="headerlink" title="对抗对手攻击的可靠性"></a>对抗对手攻击的可靠性</h2><p>对抗性攻击旨在通过精心设计的不可见干扰（对抗性样本）或预定义模式（后门触发器）使模型出错。本节概述了对$GNN$的对抗性攻击，并随后回顾了缓解此类威胁的最新工作。</p><p><strong><font color="DarkViolet">对抗性攻击可在训练阶段（中毒攻击）和推理阶段（逃避攻击）执行，以误导模型对节点等特定重要实例的预测（目标攻击），或降低模型的整体性能（非目标攻击)</font></strong>。本调查从三个维度回顾了之前的工作：操纵攻击、注入攻击和后门攻击。<strong><font color="DarkCyan">具体来说，操纵和注入攻击可以在推理阶段执行，而后门攻击总是发生在训练阶段。</font></strong></p><p>可分为三类攻击</p><ol><li>操纵攻击 <ol><li>在操纵攻击中，攻击者通过修改图结构或节点属性来生成敌对样本。例如，攻击者可以在图中添加、删除或重新布线边，以产生合法的干扰。<ol><li>一篇开创性的工作，通过贪婪搜索算法操纵图的边和属性来制作对抗性样本。</li><li>这项工作之后，基于梯度的方法成为制作对抗性样本的一种重要方法。通过利用受害者模型或局部训练的代理模型的梯度信息，攻击者可以很容易地近似最坏情况下的扰动来执行攻击</li><li>提出了一种无监督的对抗性攻击，其中梯度是基于图形对比损失计算的。</li><li>除梯度信息外，有工作近似图频谱，以黑盒方式执行攻击。</li></ol></li></ol></li><li>注入攻击<ol><li>操纵攻击要求攻击者拥有修改原始图形的高权限，这在许多真实场景中是不切实际的。或者，注入攻击最近已成为一种更实用的方法，将一些恶意节点注入到图中。注入攻击的目标是通过几个注入节点将恶意信息连同图结构一起传播到适当的节点。<ol><li>首先研究了节点注入攻击，并提出了一种基于强化学习的框架来毒害图。</li><li>有工作进一步推导出近似闭合解，以线性化攻击模型并有效注入新的恶意节点。</li><li>在规避攻击设置中，有工作同时考虑注入节点的属性和结构，以获得更好的攻击性能</li><li>最近的一项研究表明，注入攻击的成功是建立在对原始图的同源性造成严重破坏的基础上的。因此，作者提出了优化和谐敌对目标以保持图的同态性。</li></ol></li></ol></li><li>后门攻击<ol><li>与前两次攻击相比，后门攻击的目的是在训练阶段将后门触发器注入到图中，从而毒害学习模型。通常，后门触发器可以是攻击者设计的节点或（子）图。<ol><li>有工作建议使用子图作为触发模式来发起后门攻击</li><li>还有工作根据可解释性方法为$GNN$选择最佳触发器。</li></ol></li><li><strong><font color="DarkViolet">在文献中，后门攻击是一种相对未被发现的威胁。然而，在许多安全关键领域，它们更为现实和危险，因为后门触发器甚至很难被人类注意到。</font></strong></li></ol></li></ol><h3 id="方法-2"><a href="#方法-2" class="headerlink" title="方法"></a>方法</h3><p>从数据、模型和优化角度回顾$DGL$最近针对对抗性攻击的鲁棒性增强技术。</p><ol><li><p>图处理</p><ol><li><p>从数据的角度来看，一个自然的想法是处理训练/测试图，以消除敌对噪声，从而减轻其负面影响。目前，加强这方面的方法主要是通过对具体对抗性攻击的经验观察来支持的。</p><ol><li>有工作基于节点属性的$Jaccard$相似性修剪受干扰的边，假设受到不利干扰的节点与其邻居的相似性较低。</li><li>另一项工作观察到，逆扰动图的邻接矩阵总是具有高秩。基于这一观察，他们利用奇异值分解$（SVD）$对相邻矩阵进行低阶近似，从而在一定程度上减少了对抗性攻击的影响。</li><li>此外，通过在训练期间保持稀疏、低秩和特征平滑的图属性，可以同时学习干净的图结构</li></ol><p><strong><font color="DarkViolet">基于图形处理的方法实现成本低廉，同时显著提高了GNN的对抗鲁棒性。然而，基于特定攻击的经验观察使得此类方法难以抵抗不可见的攻击。此外，性能和稳健性之间还有一个特殊的权衡，因为它们通常假设数据已经受到干扰。</font></strong></p></li></ol></li><li><p>模型鲁棒性</p><ol><li>改进模型以应对潜在的敌对威胁是一种显著的增强技术，我们称之为模型鲁棒性。具体而言，$GNNs$的鲁棒性可以通过改进模型体系结构或聚合方案来实现。有几种旨在通过对模型本身采用不同的正则化或约束来改进体系结构的努力<ol><li>$1-Lipschitz约束$</li><li>基于$\ell_1$的图平滑</li><li>自适应残差</li><li>最近的工作，$GNNs$聚集邻域信息进行表征学习的方式使其容易受到对抗性攻击。为了解决这 个问题，他们推导了一个稳健的中值函数，而不是均值函数，以改进聚合方案。总的来说，一个健壮的模型能够抵抗对手攻击，而不会在良性情况下影响性能。</li></ol></li></ol></li><li><p>鲁棒性训练</p><ol><li><p>另一种成功应用于$GNN$模型的增强技术是基于稳健的训练范式。对抗性训练是一种广泛使用的对抗性攻击的实用解决方案，它在训练集上构建模型，并添加手工制作的对抗性样本。本质上，敌对样本可以通过对图结构的特定扰动、节点属性甚至隐藏表示来构建。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">其实就是在训练的时候人为的制造一些样本，来让模型在学习的时候也注意到</span><br></pre></td></tr></table></figure><p><strong><font color="DarkViolet">虽然对抗性训练可以提高模型的泛化能力和鲁棒性，以抵抗不可见的攻击，但存在过度拟合对抗性样本的风险。</font></strong>此外，对抗性训练只能抵抗躲避攻击。为此，有工作建议通过传输类似图域的知识来增强模型对中毒攻击的鲁棒性。然而，它需要来自其他领域的大量干净的图来成功地训练模型</p></li></ol></li></ol><hr><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><h3 id="未来方向"><a href="#未来方向" class="headerlink" title="未来方向"></a>未来方向</h3><ol><li>尽管可靠DGL的算法有所进步，但仍然缺乏正式分析这些方法有效性的理论框架。例如，如何分析$DGL$设置中的分布外泛化边界仍然是一个悬而未决的问题。</li><li>在现实世界中，这些威胁可能同时发生。因此，需要一个统一的解决方案来缓解这些威胁造成的影响</li><li>鲁棒性和学习稳定性之间有着密切的联系。因此，从优化的角度来看，如何为$DGL$构建鲁棒的学习算法也是一个有趣的方向。</li><li>现有的对抗性攻击可靠性研究主要集中在相对较小的图上，如何将这些方法转化为真实世界的大规模图仍有待探索。</li><li>现有工作倾向于利用标准性能指标（如精度）来衡量$DGL$模型的稳健性，然而，这显然不足以评估整体可靠性性能。具有高精度的$DGL$算法可能对不同的属性组不公平，这导致不同数据组之间的精度和鲁棒性存在严重差异。这就需要在今后的工作中探索公平和稳健的$DGL$算法，并开发出超越准确性的原则性评估指标。</li><li>$DGL$算法的一个问题是缺乏可解释性。为了解决这个问题，提出了反事实解释，作为理解算法如何做出决策的有力手段。虽然先前对视觉任务的研究表明，反事实解释和对抗性样本是具有许多相似性的密切相关的方法，但目前在$DGL$中系统地探索它们之间的联系的工作很少。</li><li>随着可靠的DGL算法的快速发展，研究社区需要真实世界的基准测试。一些特定环境的早期基准已经建立，例如，有工作提出了一个面向对象的数据集管理器和AI辅助药物发现的基准，该数据集管理器和基准专门针对数据噪音的分布转移问题而设计。有希望建立一个通用的基准平台，以涵盖本次调查中提到的更多可靠性方面。</li></ol>]]></content>
      
      
      <categories>
          
          <category> Paper Reading </category>
          
          <category> Graph Neural Networks </category>
          
          <category> Attacks and defends </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GNNs </tag>
            
            <tag> Attacks and defends </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Word2vec(Google 2013)</title>
      <link href="/2022/05/24/word2vec/"/>
      <url>/2022/05/24/word2vec/</url>
      
        <content type="html"><![CDATA[<p><strong><font color="LightCoral">paper</font></strong>:</p><ol><li><a href="https://arxiv.org/abs/1301.3781">https://arxiv.org/abs/1301.3781</a><br>explain: <a href="https://so.csdn.net/so/search?q=word2vec&amp;spm=1001.2101.3001.7020">word2vec</a>的奠基性论文之一，由Google的Tomas Mikolov提出。该论文提出了CBOW和Skip-gram两种word2vec模型结构。</li><li><a href="https://proceedings.neurips.cc/paper/2013/hash/9aa42b31882ec039965f3c4923ce901b-Abstract.html">https://proceedings.neurips.cc/paper/2013/hash/9aa42b31882ec039965f3c4923ce901b-Abstract.html</a><br>explain: word2vec的另一篇奠基性论文。详细描述了Skip-gram模型，包括模型的具体形式和Hierarchical Softmax、Negative Sampling两种可行的训练方法。</li></ol><h1 id="词表征"><a href="#词表征" class="headerlink" title="词表征"></a>词表征</h1><ol><li>$one-hot$ 表征(很难表达相似度)<ol><li>维度太大</li><li>每个元素是离散的的，要不就是0，要不就是1</li><li>$local$ 只有一位起决定作用</li></ol></li><li>分布式表示<ol><li>维度相对较低 $d \ll \left|V\right|$</li><li>每个元素不再是离散的，可以是不同的实数</li><li>并不是只有一位起作用，联合表达一个单词</li></ol></li></ol><p>Word2vec就是一种分布式表示的方法</p><h1 id="Word2vec"><a href="#Word2vec" class="headerlink" title="Word2vec"></a>Word2vec</h1><p>Training Data: corpus</p><script type="math/tex; mode=display">[\omega_1,\omega_2,\cdots,\omega_{t-1},\omega_t,\omega_{t+1},\cdots,\omega_T]</script><p>Target: 词的分布式表示</p><hr><p><strong><font color="DeepPink">接下来的分析过程是基于$skip-gram$,会提到三个假设：</font></strong></p><p>首先我们来看联合概率分布，联合概率表示为包含多个条件并且所有的条件都同时成立的概率，记作 $P(X=a,Y=b)$或 $P(a,b)$，有的书上也习惯记作$P(ab)$,<strong><font color="DeepPink">利用深度学习拟合的就是这种概率分布。</font></strong>根据公式$P(X,Y)=P(X|Y)\times P(Y)$,我们从词库中随便选择一个词，那么整个词库的概率表示应该如下所示，<strong><font color="DarkViolet">因为后面的计算会很复杂，这里为了方便计算，$\triangle$表示假设窗口大小是2C</font></strong></p><script type="math/tex; mode=display">P(\omega_{1:T})= P(\omega_t) \cdot P(context(\omega_t)|\omega_t)\triangleq P(\omega_t) \cdot P(\omega_{t-c:t-1},\omega_{t+1:t+c}|\omega_t)</script><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">补充：“似然性”和“概率”（或然性）有明确的区分：概率，用于在已知一些参数的情况下，预测接下来在观测上所得到的结果；似然性，则是用于在已知某些观测所得到的结果时，对有关事物之性质的参数进行估值，也就是说已观察到某事件后，对相关母数进行猜测。</span><br></pre></td></tr></table></figure><p><strong>似然函数（</strong>英语：$likelihood function$）是一种关于<a href="https://zh.m.wikipedia.org/wiki/统计模型">统计模型</a>中的<a href="https://zh.m.wikipedia.org/wiki/母數">参数</a>的<a href="https://zh.m.wikipedia.org/wiki/函数">函数</a>，表示模型参数中的<strong>似然性</strong></p><p>所以我们从上式可以写出$likelihood$：</p><script type="math/tex; mode=display">P(\omega_t) \cdot P(\omega_{t-c:t-1},\omega_{t+1:t+c}|\omega_t)</script><p>又因为我们不太关注$P(\omega_t)$,因为是随机取的，而且可以取遍整个词表，有$T$个，所以我们更关注后面的条件概率</p><p>所以$conditional \ likelihood$可以表示为:</p><script type="math/tex; mode=display">\prod_{t=1}^{T}P(\omega_{t-c:t-1},\omega_{t+1:t+c}|\omega_t)</script><p> <strong><font color="DarkViolet">这里假设每个条件概率之间是相互独立的</font></strong></p><p>为了化简，采用$\log$，则$average \ conditional \ likelihood$可以如下图表示：</p><script type="math/tex; mode=display">\frac{1}{T} \sum_{t=1}^{T}\log P(\omega_{t-c:t-1},\omega_{t+1:t+c}|\omega_t)</script><p><strong><font color="DarkViolet">这里做第三个假设，假设内部$P(\omega_{t+i}|\omega_t)$是独立同分布的</font></strong></p><p>于是继续化简上式为</p><script type="math/tex; mode=display">\frac{1}{T} \sum_{t=1}^{T}\log \prod_{i \in[-c,0) \cup (0,c]  }P(\omega_{t+i}|\omega_t) =  \frac{1}{T} \sum_{t=1}^{T} \sum_{i \in[-c,0) \cup (0,c]  } \log P(\omega_{t+i}|\omega_t)</script><p>到现在可以看出只要关注给定一个中心词，该中心词窗口内其他词的概率就可以，<strong><font color="DarkViolet">注意，这里窗口内的词都是独立的，不存在顺序问题(比如要先出现$\omega_{t}$再出现$\omega_{t+1}$)，这样的表示已经忽略了次序，这里都是独立的。</font></strong></p><hr><p><strong><font color="LightCoral">当然，从上面的分析我们暂时看不出来和求词表分布式表示有啥关系？接下来我们探索这个问题</font></strong></p><p>首先我们从输入输出和模型的角度来分析，先看下面这张图</p><p><br></p><p><img src="/2022/05/24/word2vec/image-20220524213551921.png" alt="image-20220524213551921"></p><p><br></p><p>首先我们选取一个中心词$\omega_i$，用$one-hot$的表示输入的话则是一个$\mathbb R^{|V| \times 1}$的向量，其中$|V|$是词表中所有单词的数量，这个向量只有在第$i$位是1，其他位全都为0。参数矩阵$W \in \mathbb R^{|V| \times d}$和$U \in \mathbb R^{d \times |V|} $，<strong><font color="DarkViolet">注意这里的$W$矩阵没有使用激活层，是线性的，为了计算简单，如果用矩阵相乘的方式，那么用$\mathbb R^{|V| \times 1}$的向量转置以后得到的$\mathbb R^{ 1 \times |V| }$向量作为输入，在模型的输出也会得到一个$\mathbb R^{ 1 \times |V| }$的向量</font></strong>，这里我们要特别理解模型的输出代表什么，如下所示：</p><script type="math/tex; mode=display">\mathbb R^{ 1 \times |V| } \stackrel{每一位的表示}\longrightarrow \left\{ P(\omega_1|\omega_i),P(\omega_2|\omega_i),P(\omega_3|\omega_i),\cdots,P(\omega_{|V|}|\omega_i)\right\}</script><p>然后使用softmax将所有概率值放在$(0，1]$区间当中，即对于中心词$\omega_{i}$，所预测的其他所有词的概率，令$softmax$之后的值为，</p><script type="math/tex; mode=display">\left\{ \hat P(\omega_1|\omega_i),\hat P(\omega_2|\omega_i),\hat P(\omega_3|\omega_i),\cdots,\hat P(\omega_{|V|}|\omega_i)\right\}</script><p>对于中心词$\omega_{i}$，所预测的其他所有词的概率之和为1：</p><script type="math/tex; mode=display">\sum_{t=1}^{|V|} \hat P(\omega_t|\omega_i)=1</script><p><img src="/2022/05/24/word2vec/image-20220524233941683.png" alt="image-20220524233941683"></p><p><br></p><p>当然我们需要在$\omega_{i}$长度为$2c$的窗口中每个上下文一个位置所有的概率值，注意下图对应的$W^{‘}$参数矩阵就是上图的$U$矩阵(注意，不是多个不同的U矩阵，都是同一个，这里为了形象化不同的上下文位置拆开了)，这里我理解假如一共有5个词，s上下文窗口有两个词对应的索引分别式1和3，则所代表的$\hat y_{target}=[0,1,0,1,0]$，在损失函数优化的时候应该用$\hat y_{target}-y_{output}$合在一起算，下面的分开算只是为了好理解，其前面的c个词和后面的c个词作为了$Skip-Gram$模型的输出,，期望这些词的$softmax$概率比其他的词大。</p><p><br></p><p><img src="/2022/05/24/word2vec/20200831235730940.png" alt></p><p><br></p><p>最后我们讨论损失函数，我们已经有了上面的似然函数，则损失函数的优化可以如下表示，因为我们要最大化中心词和上下文之间的联系概率，所以要</p><script type="math/tex; mode=display">\max \frac{1}{T} \sum_{t=1}^{T} \sum_{i \in[-c,0) \cup (0,c]  } \log P(\omega_{t+i}|\omega_t)</script><p>对上式我们取负数，则变成了最小化：</p><script type="math/tex; mode=display">\min -\frac{1}{T} \sum_{t=1}^{T} \sum_{i \in[-c,0) \cup (0,c]  } \log P(\omega_{t+i}|\omega_t)</script><p>所以损失函数即为：</p><script type="math/tex; mode=display">J(\theta)=-\frac{1}{T} \sum_{t=1}^{T} \sum_{i \in[-c,0) \cup (0,c]  } \log P(\omega_{t+i}|\omega_t)</script><p><strong><font color="Crimson">那最后该怎么得到所有词的向量呢？我们在训练的过程中不断的更新$W$和$U$的参数矩阵，在训练完成之后，用$one-hot$向量和训练好的$W$矩阵相乘就是得到的词向量了，也就是词的embedding！！！（注意，不需要$U$矩阵）</font></strong></p><p>最后</p><p><strong><font color="LightCoral">这里skip-gram的介绍就完成了，CBOW的思想类似</font></strong></p><h1 id="两个优化方法"><a href="#两个优化方法" class="headerlink" title="两个优化方法"></a>两个优化方法</h1><h2 id="Hierarchical-Softmax"><a href="#Hierarchical-Softmax" class="headerlink" title="Hierarchical Softmax"></a>Hierarchical Softmax</h2><p><strong><font color="MediumBlue">思考：如果词库特别大，也就是$|V|$特别大，那在最后计算$softmax$的计算量也会非常大，怎么办呢？</font></strong></p><p>该方法最后一层的长度不设置成$|V|$大小，而是设置成一棵树的节点数的长度，这里首先要了解$Huffman$树的构造方法和$Huffman$编码。</p><p><strong><font color="DarkViolet">这里看这个图，非常容易理解，按照词频进行节点的融合，越靠近根节点的词频越大，黄色节点是在构成树的过程当中添加的节点，注意，所有词都在叶子节点上，但非叶子节点上也要定义和叶子节点等长的向量，为了方便计算</font></strong></p><p><img src="/2022/05/24/word2vec/image-20220525010308984.png" alt="image-20220525010308984"></p><p><br></p><p><strong><font color="LightSeaGreen" size="4">$CBOW$</font></strong></p><p><br></p><p>在得到了上面的图之后，我们就可以来计算概率，首先以$CBOW$为例子，将输入层的$2c$个词向量累加求和，即</p><script type="math/tex; mode=display">X_w=\sum_{i=1}^{2c}v(context(w_i)) \quad v(context(w_i)\in \mathbb R^{m}</script><p> <strong><font color="DarkViolet">这里一定要注意，一开始死活不明白为什么用二分类乘积的方法就可以计算$w$在其上下文的条件概率，就是因为忽略了这里，其实$X_w$在二分类中已经被当作条件使用了，太蠢了，这点无知错误都没想明白</font></strong></p><p><img src="https://img-blog.csdnimg.cn/20200603202110178.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1ZhcmlhYmxlWA==,size_16,color_FFFFFF,t_70#pic_center" alt="img"></p><p><img src="/2022/05/24/word2vec/image-20220525011220421.png" alt="image-20220525011220421"></p><p><br></p><p><strong><font color="LightCoral" size="4">在得到了一个词在其上下文的概率之后，就可以扩展到整个词库，从而得到损失函数，采用随机梯度上升法将这个函数最大化。</font></strong></p><p><br></p><p><img src="/2022/05/24/word2vec/image-20220525012323049.png" alt="image-20220525012323049"></p><p><br></p><p><strong><font color="LightSeaGreen" size="4">$Skip-gram$</font></strong></p><p><br></p><p>讲完了$CBOW$，其实$Skip-gram$的思想一模一样，就是反过来了,之前的$CBOW$是根据上下文预测中间词，而$Skip-gram$是根据中间词预测上下文，即有了$X_w$来得到$p(context(w)|w)$，根据这个思想得到优化函数，其实就是要对$context(w)$的所有词概率进行相乘，和$CBOW$是反的，可以理解为一个是多对一，一个是一对多，但本质上都是为了让$w$和$context(w)$联系的更加紧密</p><p><br></p><p><img src="https://img-blog.csdnimg.cn/20200603202953553.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1ZhcmlhYmxlWA==,size_16,color_FFFFFF,t_70#pic_center" alt="img"></p><p><img src="/2022/05/24/word2vec/image-20220525013057616.png" alt="image-20220525013057616"></p><p><br></p><p>同样，采用随机梯度上升法将这个函数最大化。</p><hr><h2 id="Negative-Sampling"><a href="#Negative-Sampling" class="headerlink" title="Negative Sampling"></a>Negative Sampling</h2><p><img src="/2022/05/24/word2vec/image-20220525014133991.png" alt="image-20220525014133991"></p><p><br></p><p><strong><font color="LightSeaGreen" size="4">$CBOW$</font></strong></p><p><br></p><p><img src="/2022/05/24/word2vec/image-20220525014312156.png" alt="image-20220525014312156"></p><p><img src="/2022/05/24/word2vec/image-20220525014343905.png" alt="image-20220525014343905"></p><p><br></p><p><strong><font color="LightSeaGreen" size="4">$Skip-gram$</font></strong></p><p><br></p><p><img src="/2022/05/24/word2vec/image-20220525014705835.png" alt="image-20220525014705835"></p><p><img src="/2022/05/24/word2vec/image-20220525014728040.png" alt="image-20220525014728040"></p><p><br></p><p><strong><font color="LightSeaGreen" size="4">如何负采样</font></strong></p><p><br></p><p>上面个介绍了CBOW和skip-gram的负采样方法，那刚才的遗留问题，究竟怎样负采样呢？</p><p><img src="/2022/05/24/word2vec/image-20220525015241713.png" alt="image-20220525015241713"></p><p><img src="/2022/05/24/word2vec/image-20220525015246285.png" alt="image-20220525015246285"></p><p><br></p><p>参考资料：</p><ol><li><p><a href="https://www.cnblogs.com/peghoty/p/3857839.html">https://www.cnblogs.com/peghoty/p/3857839.html</a></p></li><li><p><a href="https://blog.csdn.net/VariableX/article/details/106531987">https://blog.csdn.net/VariableX/article/details/106531987</a></p></li><li><p><a href="https://www.bilibili.com/video/BV1hy4y1n7ik?p=3&amp;spm_id_from=pageDriver">https://www.bilibili.com/video/BV1hy4y1n7ik?p=3&amp;spm_id_from=pageDriver</a></p><p>explain:白板推导系列很不错</p></li></ol><hr><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><strong><font color="LightCoral" size="4">这一次下了比较大的功夫，终于对word2vec有一个比较深入的理解了，之前总是看了一知半解，不够认真，学东西的时候一定更沉下心，要不就是在浪费时间，原理明白了，但是对代码的实现还差的很远，继续加油吧。</font></strong></p>]]></content>
      
      
      <categories>
          
          <category> Paper Reading </category>
          
          <category> Natural Language Processing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DCRNN(ICLR 2018)</title>
      <link href="/2022/05/23/DCRNN/"/>
      <url>/2022/05/23/DCRNN/</url>
      
        <content type="html"><![CDATA[<p><font color="VioletRed">paper</font>:<a href="https://arxiv.org/abs/1707.01926">https://arxiv.org/abs/1707.01926</a></p><p><font color="VioletRed">code</font>:<a href="https://github.com/liyaguang/DCRNN/">https://github.com/liyaguang/DCRNN/</a></p><h2 id="所解决的问题"><a href="#所解决的问题" class="headerlink" title="所解决的问题"></a>所解决的问题</h2><ol><li>复杂的路网空间依赖性</li><li>随着路况变化非线性变化的动态时间依赖性</li><li>长期预测本身就存在的内在的困难。</li></ol><p>这项工作使用一个<strong><font color="DarkViolet">有向图来表示交通传感器之间的成对空间相关性，该图的节点是传感器，边权重表示通过道路网络距离测量的传感器对之间的接近度。</font></strong>我们将交通流动力学建模为一个扩散过程，并提出了扩散卷积运算来捕获空间依赖性。我们进一步提出了扩散卷积递归神经网络（DCRNN），它集成了扩散卷积、序列到序列结构和定时采样技术。</p><h2 id="问题定义"><a href="#问题定义" class="headerlink" title="问题定义"></a>问题定义</h2><p>交通预测的目标是根据之前从道路网络上的N个相关传感器观测到的交通流量，预测未来的交通速度。我们可以将传感器网络表示为加权有向图$\mathcal G=(\mathcal V,\mathcal E,W )$，其中$\mathcal V$是一组节点$\left|\mathcal V \right|=N$，$\mathcal E$是一组边，$W \in \mathbb R^{N \times N}$是表示节点接近度的加权邻接矩阵（例如，其道路网络距离的函数）,将$\mathcal G$上观察到的交通流表示为图形信号$X \in \mathbb R^{N \times P}$，其中P是每个节点的特征数（例如速度、体积）。假设$X^{(t)}$表示在时间t观察到的图形信号，交通预测问题旨在学习一个函数$h(\cdot)$，该函数将之前的$T^{‘}$个历史图形信号映射到未来的$T$个图形信号，给定一个图G：</p><script type="math/tex; mode=display">\begin{equation}[X^{(t-T'+1)},\cdots, X^{(t)};\mathcal G] \stackrel{h(\cdot)}{\longrightarrow}[X^{(t+1)},\cdots, X^{(T)}]\end{equation}</script><h2 id="空间依赖性"><a href="#空间依赖性" class="headerlink" title="空间依赖性"></a>空间依赖性</h2><p>通过将交通流关联到扩散过程来建模空间依赖性，该过程明确捕获了交通动力学的随机性质。该扩散过程的特征是$\mathcal G$上的随机游动，restart概率为$\alpha \in [0,1]$和状态转移矩阵$D_0^{-1}W$。这里$D_0=diag(W1)$是出度对角矩阵，其中$1\in \mathbb R^{N}$是全为1的向量，<strong><font color="DarkViolet">如同马尔可夫过程一样，这个随机游走在游走了足够长的步数后能得到一个稳定的分布$\mathcal{P}\in\mathbb{R}^{N\times N}$，在这个分布中的每一行$\mathcal{P}_{i,:}\in\mathbb{R}^{N}$,表示节点$i$与其余节点的相似性。</font></strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">补充：这块内容其实在PPNP&amp;APPNP那篇里介绍过，在jk-net那篇论文里有证明说GCN获得的表征最终会与随机游走获得的稳定分布一致，但传统随机游走由于没考虑restart，使得其在表征起始节点上并不好，所以该模型加入了一个restart的概率来改进。</span><br></pre></td></tr></table></figure><p>这个稳定分布用数学公式表示为：</p><script type="math/tex; mode=display">\begin{equation}\mathcal P = \sum_{\mathcal k=0}^{\infty}\alpha(1-\alpha)^k(D_O^{-1}W)^k\end{equation}</script><p>其中$k$是扩散步数。在实践中，我们使用扩散过程的有限$k$步截断，并为每个步骤指定一个可训练的权重。<strong><font color="DarkViolet">在实际模型中，还会利用入度矩阵再求一次，以更充分地捕获双向（upstream和downstream）的信息。（注意，是有向图，所以按入度和出度划分）</font></strong></p><h2 id="扩散卷积"><a href="#扩散卷积" class="headerlink" title="扩散卷积"></a><strong>扩散卷积</strong></h2><p>$X \in \mathbb R^{N \times P}$ 和过滤器 $f_{\theta}$ 被定义为:</p><script type="math/tex; mode=display">X_{:,p\,\star \mathcal G} \,f_{\theta}=\sum_{k=0}^{K-1}(\theta_{k,1}(D_O^{-1}W)^k+ \theta_{k,2}(D_I^{-1}W^T)^k)X_{:,p} \quad for \ \mathcal p\in \left\{ 1,\cdots,P \right\}</script><p>这里的$D_O^{-1}W$和$D_I^{-1}W^T$分别是由上面的出度、入度扩散操作所得的稳定分布，式中$\theta \in \mathbb R^{K \times 2}$是滤波器的参数,上式的计算如果$\mathcal G$是稀疏矩阵，可以使用递归稀疏稠密矩阵的计算方式大大减低计算复杂度。证明可以看论文详细介绍。</p><h2 id="扩散卷积层"><a href="#扩散卷积层" class="headerlink" title="扩散卷积层"></a><strong>扩散卷积层</strong></h2><p>利用上式中定义的卷积运算，我们可以建立一个扩散卷积层，将$P$维特征映射到$Q$维输出。其中定义参数张量为$\Theta \in \mathbb R^{Q \times P \times K \times 2} = [\theta]_{q,p}$是用来进行维度转化的参数， $\Theta_{q,p,:,:} \in \mathbb R^{K \times 2}$是参数化第$p$维输入和第$q$维输出的卷积滤波器。因此，扩散卷积层为：</p><script type="math/tex; mode=display">H_{:,q}=a(\sum_{p=1}^P X_{;,q \ \star \mathcal G}\ f_{\theta_{q,p,:,:}}) \quad for \ q\in \left\{ 1, \cdots,Q \right\}</script><p>值得一提的是，文章里提到了扩散卷积层与频域GCN的关系。文中指出，ChebNet实际上是扩散卷积的一种特例。$X \in \mathbb R^{N \times P}$是输入，$H \in \mathbb R^{N \times Q}$是输出，扩散卷积层学习图结构数据的表示，我们可以使用基于随机梯度的方法对其进行训练。</p><h2 id="时间依赖性"><a href="#时间依赖性" class="headerlink" title="时间依赖性"></a><strong>时间依赖性</strong></h2><p>利用递归神经网络（RNN）来建模时间依赖性。特别是，我们使用门控循环单元（GRU），这是RNN的一种简单而强大的变体。我们将GRU中的矩阵乘法替换为扩散卷积，从而提出了扩散卷积门控循环单元（DCGRU）。</p><hr><h3 id="GRU补充知识："><a href="#GRU补充知识：" class="headerlink" title="GRU补充知识："></a>GRU补充知识：</h3><p>GRU 原论文：<a href="https://arxiv.org/pdf/1406.1078v3.pdf">https://arxiv.org/pdf/1406.1078v3.pdf</a><br>GRU不错的理解：<a href="https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be">https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be</a></p><p>GRU 背后的原理与 LSTM 非常相似，即用门控机制控制输入、记忆等信息而在当前时间步做出预测，表达式由以下给出：</p><script type="math/tex; mode=display">z=\sigma(x_tU^z + s_{t-1}W^z) \\r=\sigma(x_tU^T + S_{t-1}W^r) \\h=tanh(x_tU^T + S_{t-1}\circ W^h) \\s_t=(1-z)\circ h+ z \circ_{t-1}</script><p>GRU 有两个有两个门，即一个重置门（reset gate）和一个更新门（update gate）。从直观上来说，重置门决定了如何将新的输入信息与前面的记忆相结合，更新门定义了前面记忆保存到当前时间步的量。如果我们将重置门设置为 1，更新门设置为 0，那么我们将再次获得标准 RNN 模型。</p><h4 id="更新门"><a href="#更新门" class="headerlink" title="更新门"></a>更新门</h4><p>在时间步 t，我们首先需要使用以下公式计算更新门 $z_t$：</p><script type="math/tex; mode=display">z_t=\sigma(W^{(z)}x_t + U^{(z)}h_{t-1})</script><p>其中 $x_t$为第 $t$ 个时间步的输入向量，即输入序列 $X$的第 $t$个分量，它会经过一个线性变换（与权重矩阵 $W^{(z)}$相乘）。$h_{t-1} $保存的是前一个时间步 $t-1 $的信息，它同样也会经过一个线性变换。更新门将这两部分信息相加并投入到 $\sigma$ 激活函数中，因此将激活结果压缩到 0 到 1 之间。</p><p><strong><font color="Salmon">更新门帮助模型决定到底要将多少过去的信息传递到未来，或到底前一时间步和当前时间步的信息有多少是需要继续传递的。这一点非常强大，因为模型能决定从过去复制所有的信息以减少梯度消失的风险。</font></strong></p><h4 id="重置门"><a href="#重置门" class="headerlink" title="重置门"></a>重置门</h4><p>重置门主要决定了到底有多少过去的信息需要遗忘，我们可以使用以下表达式计算：</p><script type="math/tex; mode=display">r_t=\sigma(W^{(r)}x_t + U^{(r)}h_{t-1})</script><p><strong><font color="DarkViolet">该表达式与更新门的表达式是一样的，只不过线性变换的参数和用处不一样而已。</font></strong></p><h4 id="当前记忆内容"><a href="#当前记忆内容" class="headerlink" title="当前记忆内容"></a>当前记忆内容</h4><p>在重置门的使用中，新的记忆内容将使用重置门储存过去相关的信息，它的计算表达式为：</p><script type="math/tex; mode=display">h_t^{'}=tanh(Wx_t + r_t\circ Uh_{t-1})</script><p>输入$x_t$与上一时间步信息 $h_{t-1} $先经过一个线性变换，即分别右乘矩阵 W 和 U。计算重置门 $r_t$ 与 $Uh_{t-1}$ 的 Hadamard 乘积，即$r_t$ 与 $Uh_{t-1}$ 的对应元素乘积。<strong><font color="DarkViolet">因为前面计算的重置门是一个由 0 到 1 组成的向量，它会衡量门控开启的大小。例如某个元素对应的门控值为 0，那么它就代表这个元素的信息完全被遗忘掉。该 Hadamard 乘积将确定所要保留与遗忘的以前信息。</font></strong></p><h4 id="当前时间步的最终记忆"><a href="#当前时间步的最终记忆" class="headerlink" title="当前时间步的最终记忆"></a>当前时间步的最终记忆</h4><p>在最后一步，网络需要计算$ h_t$，该向量将保留当前单元的信息并传递到下一个单元中。在这个过程中，我们需要使用更新门，它决定了当前记忆内容和$h_{t}^{‘}$前一时间步 $h_{t-1}$ 中需要收集的信息是什么。</p><script type="math/tex; mode=display">h_t= z_t \odot h_{t-1} + (1-z_t) \odot h_t^{'}</script><p>现在我们有了<strong><font color="Salmon">当前记忆</font></strong>保留至最终记忆的信息$h_{t}^{‘}$，$z_t $与 $h_{t-1}$ 的 Hadamard 乘积表示<strong><font color="Salmon">前一时间步</font></strong>保留到最终记忆的信息</p><p><img src="/2022/05/23/DCRNN/GRU%20ALL.png" alt="GRU ALL"></p><p>门控循环单元不会随时间而清除以前的信息，它会保留相关的信息并传递到下一个单元，因此它利用全部信息而避免了梯度消失问题。</p><hr><p>回到DCRNN当中，我们将GRU中的矩阵乘法替换为扩散卷积，从而提出了扩散卷积选通递归单元（DCGRU）。公式如下：</p><script type="math/tex; mode=display">r^{(t)}=\sigma(\Theta_{r\ \star \mathcal G}[X^{(t)},H^{(t-1)}]+ b_r) \\u^{(t)}=\sigma(\Theta_{r\ \star \mathcal G}[X^{(t)},H^{(t-1)}]+ b_u) \\C^{(t)}=\tanh(\Theta_{C\ \star \mathcal G}[X^{(t)},(r^{(t)} \odot H^{(t-1)})]+ b_c) \\H^{(t)}= u^{(t)} \odot H^{(t-1)} + (1-u^{(t)}) \odot C^{(t)}</script><p>之后为了进行预测，模型在这一块设计成了$Seq2Seq$的形式。同时，为了提升$Seq2Seq$的效果，模型引入了$schedule sample$，为什么$schedule sample$能提升效果呢？原因如下：</p><p>$seq2seq$模型在训练和预测的时候实际上存在着差异，在训练过程中，是将已有的正确的序列输入进行预测，而在预测层中，则是根据上一轮生成的结果进行预测，如果上一轮结果错误，那么后续接连错误的概率就会很大。为了解决这个问题，$schedule sample$设定了一个概率$p$，使得在训练的过程中，有$p$的概率使用训练样本，有$1-p$的概率使用上一轮生成的结果进行预测。在DCRNN的训练策略中，还会随着训练的次数加深不断降低$p$，直到$p$为0，这样就使得模型能很好地适应预测阶段的模式。</p><p><strong><font color="SandyBrown">参考</font></strong>：这个作者的理解，挺不错的 <a href="https://www.ooordinary.com/post/dcrnn">https://www.ooordinary.com/post/dcrnn</a></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>第一篇时空图神经网络的文章，其实在序列这里一直是短板，没能理解是怎么序列实现的，自己又懒，一定要看一下RNN和$seq2seq$的代码实现</p><p>本篇文章主要理解的就是两个点：</p><ol><li><strong><font color="Salmon">随机游走得到稳定分布并利用扩散卷积</font></strong></li><li><strong><font color="Salmon">对时间依赖性GRU单元的理解和DCGRU的理解</font></strong></li></ol>]]></content>
      
      
      <categories>
          
          <category> Paper Reading </category>
          
          <category> Graph Neural Networks </category>
          
          <category> spatiotemporal sequences </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GNNs </tag>
            
            <tag> spatiotemporal sequences </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pro-GNN(KDD 2020)</title>
      <link href="/2022/05/21/Pro-GNN/"/>
      <url>/2022/05/21/Pro-GNN/</url>
      
        <content type="html"><![CDATA[<p><font color="VioletRed">paper</font>:<a href="https://arxiv.org/abs/2005.10203">https://arxiv.org/abs/2005.10203</a></p><p><font color="VioletRed">code</font>:</p><ol><li><a href="https://github.com/ChandlerBang/Pro-GNN/">https://github.com/ChandlerBang/Pro-GNN/</a></li><li><a href="https://github.com/DSE-MSU/DeepRobust/blob/2bcde200a5969dae32cddece66206a52c87c43e8/deeprobust/graph/defense/prognn.py">https://github.com/DSE-MSU/DeepRobust/blob/2bcde200a5969dae32cddece66206a52c87c43e8/deeprobust/graph/defense/prognn.py</a> </li></ol><p>GNN容易受到精心设计的干扰，称为对抗性攻击。对抗性攻击很容易欺骗GNN对下游任务进行预测。因此，开发鲁棒算法来防御对抗性攻击具有重要意义。防御对抗性攻击的一个自然想法是<strong><font color="DarkViolet">清除扰动图</font></strong>。很明显，真实世界的图具有一些固有的特性。例如，许多真实世界的图是<strong><font color="DarkViolet">低秩和稀疏的</font></strong>，并且两个相邻节点的特征往往相似。提出了一个通用框架Pro-GNN，它<strong><font color="DarkViolet">可以在这些属性的指导下，从扰动图中联合学习结构图和鲁棒图神经网络模型</font></strong>。</p><h2 id="探索低秩和稀疏性属性"><a href="#探索低秩和稀疏性属性" class="headerlink" title="探索低秩和稀疏性属性"></a>探索低秩和稀疏性属性</h2><p>许多现实世界的图自然是低等级和稀疏的，因为实体通常倾向于形成社区，并且只与少数邻居相连，<strong><font color="DarkViolet">对GCN的对抗性攻击往往会增加连接不同社区节点的对抗性边缘，因为这样可以更有效地降低GCN的节点分类性能</font></strong>。因此，为了从有噪声和扰动的图中恢复干净的图结构，一种可能的方法是通过强制使用具有低秩和稀疏性的<strong>新邻接矩阵S</strong>来学习接近中毒图邻接矩阵的干净邻接矩阵。给定中毒图的邻接矩阵A，我们可以将上述过程表述为结构学习问题：</p><script type="math/tex; mode=display">\begin{equation}    \mathop{\arg\min}_{S \in \mathcal S} \ \mathcal L_0 = \left\|A-S\right\|_F^2 + R(S) \quad s.t.,S=S^\mathsf{T} \end{equation}</script><p>由于对抗性攻击的目标是对图形执行<strong><font color="DarkViolet">不可见的干扰</font></strong>，因此第一项$\left|A-S\right|_F^2$确保新邻接矩阵S应接近A，由于我们假设图是无向的，新邻接矩阵应是对称的，即$S=S^\mathsf{T}$, R(S)表示S上的约束，以增强低秩和稀疏性的性质，那R(S)该如何定义呢？根据一些研究，<strong><font color="DarkViolet">最小化矩阵的1范数和核范数可以分别强制矩阵稀疏和低秩</font></strong>。因此上式就可变为</p><script type="math/tex; mode=display">\begin{equation}    \mathop{\arg\min}_{S \in \mathcal S} \ \mathcal L_0 = \left\|A-S\right\|_F^2 + \alpha \left\|S\right\|_1 +\beta \left\|S\right\|_* \quad s.t.,S=S^\mathsf{T} \end{equation}</script><p>其中，$\alpha$和$\beta$是预定义的参数，<strong><font color="DarkViolet">分别控制稀疏性和低秩属性的贡献</font></strong>。最大限度地减少核范数$\left|S\right|_*$的一个重要好处是我们可以减少每一个奇异值，从而减轻对抗性攻击扩大奇异值的影响。</p><h2 id="探索特征平滑度"><a href="#探索特征平滑度" class="headerlink" title="探索特征平滑度"></a>探索特征平滑度</h2><p>很明显，图中的连接节点可能具有相似的特征。事实上，这种观察是在许多领域的图上进行的。例如，社交图中的两个连接用户可能共享相似的属性，网页图中的两个链接网页往往具有相似的内容，引文网络中的两篇连接论文通常具有相似的主题。同时，最近有证据表明，<strong><font color="DarkViolet">对图的对抗性攻击倾向于连接具有不同特征的节点</font></strong>。因此，我们的目标是确保所学习到的图中的特征平滑。特征平滑度可通过以下术语$\mathcal L_s$获得</p><script type="math/tex; mode=display">\begin{equation}     \mathcal L_s = \frac{1}{2}\sum_{i,j=1}^{N}S_{ij}(x_i-x_j)^2\end{equation}</script><p>其中S是新的邻接矩阵，$S_{ij}$表示学习图中$v_i$和$v_j$的连接，以及$(x_i-x_j)^2$测量$v_i$和$v_j$之间的特性差异。$\mathcal L_s$可以重写为：</p><script type="math/tex; mode=display">\begin{equation}     \mathcal L_s = tr(X^\mathsf{T}LX)\end{equation}</script><p>其中$L=D− S$是$S$图的Laplacian矩阵，$D$是$S$的对角矩阵。在这项工作中，我们使用归一化Laplacian矩阵$\hat L=D^{-1/2}LD^{-1/2}$而不是L，以使特征平滑度独立于图形节点的度数，所以此时的$\mathcal L_s$就变成了如下的形式：</p><script type="math/tex; mode=display">\begin{equation}     \mathcal L_s = tr(X^\mathsf{T}\hat LX) = \frac{1}{2}\sum_{i,j=1}^{N}S_{ij}(\frac{x_i}{\sqrt{d_i}} - \frac{x_j}{\sqrt{d_j}})^2\end{equation}</script><p>其中$d_i$表示学习图中$v_i$的阶数，在学习到的图中，如果$v_i$和$v_j$是连接的(即$S_{ij}\neq0$)，即特征差异$(x_i-x_j)^2$应较小。换言之，如果两个连接的节点之间的特征非常不同，$\mathcal L_s$非常大。因此，$\mathcal L_s$越小，图$\mathcal S$上的特征X越平滑。因此，为了实现所学习图中的特征平滑，我们应该最小化$\mathcal L_s$。因此，我们可以将特征平滑度项添加到的目标函数中，以惩罚相邻节点之间特征的快速变化，如下所示</p><script type="math/tex; mode=display">\begin{equation}    \mathop{\arg\min}_{S \in \mathcal S} \ \mathcal L = \mathcal L_0 + \lambda\mathcal L_s =\mathcal L_0 + \lambda tr(X^\mathsf{T}LX) \quad s.t.,S=S^\mathsf{T} \end{equation}</script><p>其中$\lambda$是一个预定义参数，用于控制特征平滑度的贡献。</p><h2 id="Pro-GNN的目标函数"><a href="#Pro-GNN的目标函数" class="headerlink" title="Pro-GNN的目标函数"></a>Pro-GNN的目标函数</h2><p>首先通过上面的式子从中毒图中学习一个图，然后用所学习的图训练GNN模型。然而，在这种两阶段策略下，对于给定任务的GNN模型，学习的图可能是次优的。因此，我们提出了一种更好的策略来联合学习特定下游任务的图结构和GNN模型。我们的经验表明，<strong><font color="DarkViolet">联合学习GNN模型和邻接矩阵优于两阶段</font></strong>。Pro-GNN的最终目标函数如下所示</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">简单说就是两阶段是先对图进行净化，再用这个图去训练GNN，而现在联合学习，一边训练一边优化</span><br></pre></td></tr></table></figure><script type="math/tex; mode=display">\begin{equation}    \mathop{\arg\min}_{S \in \mathcal S,\theta} \ \mathcal L = \mathcal L_0 + \lambda\mathcal L_s + \gamma\mathcal L_{GNN}  = \left\|A-S\right\|_F^2 + \alpha \left\|S\right\|_1 +\beta \left\|S\right\|_* + \lambda tr(X^\mathsf{T}\hat LX) + \gamma\mathcal L_{GNN}(\theta,\mathcal S,X,\mathcal Y_L)  \quad s.t.,S=S^\mathsf{T} \end{equation}</script><p>该公式的另一个好处是，来自$\mathcal L_{GNN}$还可以指导图形学习过程，以抵御对抗性攻击，因为图形对抗性攻击的目标是最大化$\mathcal L_{GNN}$,所以我们在防御的时候要将这个值变小.</p><p>下面是Pro-GNN的整体框架图，非常的好理解</p><p><img src="/2022/05/21/Pro-GNN/Pro-GNN.png" alt></p><h2 id="优化方法"><a href="#优化方法" class="headerlink" title="优化方法"></a>优化方法</h2><p>联合优化等式上述等式中的$\theta$和$\mathcal S$是一项挑战。对$\mathcal S$的限制进一步加剧了这一困难。因此，在这项工作中，我们使用<strong><font color="DarkViolet">交替优化模式来迭代更新θ和S</font></strong>。</p><h3 id="更新-theta"><a href="#更新-theta" class="headerlink" title="更新$\theta$"></a>更新$\theta$</h3><p>为了更新θ，固定S并删除与θ无关的项，然后目标函数减少为：</p><script type="math/tex; mode=display">\min_\theta \mathcal L_{GNN}(\theta,S,X,\mathcal Y_l) = \sum_{\mathcal u \in\mathcal V_L} \ell(f_\theta(X,S)_u,\mathcal y_u)</script><p>这是一个典型的GNN优化问题，我们可以通过随机梯度下降来学习$\theta$。</p><h3 id="更新-mathcal-S"><a href="#更新-mathcal-S" class="headerlink" title="更新$\mathcal S$"></a>更新$\mathcal S$</h3><p>类似地，为了更新$\mathcal S$，我们固定$\theta$并得出</p><script type="math/tex; mode=display">\min_S \mathcal L(S,A) + \alpha \left\|S\right\|_1 +\beta \left\|S\right\|_* \quad s.t.,S=S^\mathsf{T}</script><p>其中第一项为</p><script type="math/tex; mode=display">\mathcal L(S,A)= \left\|A-S\right\|_F^2 +  \gamma\mathcal L_{GNN}(\theta,\mathcal S,X,\mathcal Y_L) + \lambda tr(X^\mathsf{T}\hat LX)</script><p>请注意，<strong><font color="DarkViolet">ℓ1范数和核范数是不可微的</font></strong>。对于只有一个非微分正则化子R(S)的优化问题，我们可以使用前向-后向分裂方法（<strong><font color="FireBrick">具体实现请看论文和代码</font></strong>）。想法是交替使用梯度下降步骤和近似步骤</p><h1 id="总结："><a href="#总结：" class="headerlink" title="总结："></a><strong>总结：</strong></h1><p>本笔记重在理解两个部分</p><ol><li><strong><font color="Salmon">对中毒图的净化方法，包括控制低秩稀疏的$\ell_1$范数和核范数，还有特征平滑的方法</font></strong></li><li><strong><font color="Salmon">交替优化代替两阶段优化的优化方法</font></strong></li></ol>]]></content>
      
      
      <categories>
          
          <category> Paper Reading </category>
          
          <category> Graph Neural Networks </category>
          
          <category> Attacks and defends </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GNNs </tag>
            
            <tag> Attacks and defends </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
